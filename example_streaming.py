#!/usr/bin/env python3
"""
Example script demonstrating streaming dataset functionality.

This script shows how to use the new streaming dataset feature to train
AlbertMoE models on large datasets without loading them entirely into memory.
"""

import argparse
import sys

def main():
    """Demonstrate streaming dataset usage."""
    print("üöÄ AlbertMoE Streaming Dataset Example")
    print("=" * 50)
    
    print("\nüìñ Streaming Dataset Training Examples:")
    
    print("\n1Ô∏è‚É£ Basic streaming training with CLM:")
    print("python scripts/train_clm.py \\")
    print("    --mode pretrain \\")
    print("    --dataset wikitext \\")
    print("    --dataset_config wikitext-103-raw-v1 \\")
    print("    --streaming \\")
    print("    --max_samples 10000 \\")
    print("    --batch_size 8 \\")
    print("    --num_epochs 1 \\")
    print("    --hidden_size 768 \\")
    print("    --num_experts 8")
    
    print("\n2Ô∏è‚É£ Streaming training with custom dataset:")
    print("python scripts/train_clm.py \\")
    print("    --mode pretrain \\")
    print("    --dataset squad \\")
    print("    --dataset_config plain_text \\")
    print("    --text_column context \\")
    print("    --streaming \\")
    print("    --max_samples 5000 \\")
    print("    --batch_size 4 \\")
    print("    --num_epochs 2")
    
    print("\n3Ô∏è‚É£ Streaming MLM training:")
    print("python scripts/train_mlm.py \\")
    print("    --mode pretrain \\")
    print("    --dataset c4 \\")
    print("    --dataset_config en \\")
    print("    --streaming \\")
    print("    --max_samples 20000 \\")
    print("    --batch_size 16 \\")
    print("    --use_wandb")
    
    print("\n4Ô∏è‚É£ Streaming with Hub integration:")
    print("python scripts/train_clm.py \\")
    print("    --dataset oscar \\")
    print("    --dataset_config unshuffled_deduplicated_en \\")
    print("    --streaming \\")
    print("    --max_samples 50000 \\")
    print("    --batch_size 8 \\")
    print("    --push_to_hub username/albert-moe-oscar \\")
    print("    --hub_token your_hf_token")
    
    print("\nüìã Key Benefits of Streaming:")
    print("   ‚úÖ Memory efficient - doesn't load entire dataset")
    print("   ‚úÖ Works with large datasets (100GB+ datasets)")
    print("   ‚úÖ Faster startup time")
    print("   ‚úÖ Controllable dataset size with --max_samples")
    print("   ‚úÖ Supports any Hugging Face dataset")
    
    print("\n‚ö†Ô∏è  Important Notes:")
    print("   ‚Ä¢ Streaming datasets cannot be shuffled traditionally")
    print("   ‚Ä¢ Use --max_samples to limit dataset size")
    print("   ‚Ä¢ Some datasets may require specific --text_column")
    print("   ‚Ä¢ Progress bars show processed batches, not total dataset size")
    
    print("\nüí° Tips for Large Dataset Training:")
    print("   ‚Ä¢ Start with small --max_samples to test")
    print("   ‚Ä¢ Use appropriate --batch_size for your GPU memory")
    print("   ‚Ä¢ Enable --use_wandb for monitoring")
    print("   ‚Ä¢ Consider using gradient accumulation for large effective batch sizes")

if __name__ == "__main__":
    main()